#!/usr/bin/env python3

import scrapy.crawler
import spider.spider
import argparse
import ludocid.ludocid
import logging

# e.g. args.search "Aspria Berlin Ku'damm"
# e.g. ldocid=3435981545910666830

parser = argparse.ArgumentParser()
parser.add_argument("-l", "--ludocid", help="cid of the business whose review are to be scraped", type=int)
parser.add_argument("-s", "--search", help="search term")
parser.add_argument("-o", "--output", help="the CSV file name of the file where the output is stored")
args = parser.parse_args()


if __name__ == "__main__":
    if args.ludocid:
        if args.search:
            logging.error("both arguments --search and --ludocid cannot be supplied simultaneously")
            quit()
        else:
            ludocid = args.ludocid
    elif args.search:
        try:
            cid = ludocid.ludocid.cid(args.search)
            logging.debug("ludocid={cid}")
            # specify the exception
        except TypeError:
            logging.error("no result found for the specified search term")
            quit()
    else:
        logging.error("either the argument --search or --ludocid must be supplied")
        quit()

    process = scrapy.crawler.CrawlerProcess(settings={"REQUEST_FINGERPRINTER_IMPLEMENTATION": "2.7"})
    if args.output:
        process.crawl(spider.spider.ReviewSpider, ludocid=cid, csv_filename=args.output)
    else:
        process.crawl(spider.spider.ReviewSpider, ludocid=cid)
    process.start()